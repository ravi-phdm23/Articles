{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNcOQUvE9nS7CwB8FbHp5Pf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ravi-phdm23/Articles/blob/main/NLP_for_literature_review.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To categorize the research articles based on the given sample data using unsupervised learning and NLP techniques, here is a structured approach. This Python code will employ clustering based on text features extracted from the concatenated columns of each article (Title, Abstract, Keywords, etc.) and then use similarity with predefined themes to assign categories.\n",
        "\n",
        "### Step-by-Step Approach\n",
        "\n",
        "1. **Data Loading and Preprocessing**: Load the CSV data and preprocess it by concatenating relevant columns.\n",
        "2. **Text Vectorization**: Convert the concatenated text into numerical format using `TF-IDF Vectorization`.\n",
        "3. **Unsupervised Clustering (KMeans)**: Apply KMeans clustering to identify groups of articles based on their content.\n",
        "4. **Theme Matching with Cosine Similarity**: Assign each cluster to the closest theme based on similarity to pre-defined keywords.\n",
        "\n",
        "### Sample Code\n",
        "\n",
        "```python\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Load the data\n",
        "df = pd.read_csv(\"scopus_198 - selected columns.csv\")\n",
        "\n",
        "# Combine all text columns for clustering\n",
        "df['Combined_Text'] = df['Title'].fillna('') + ' ' + df['Abstract'].fillna('') + ' ' + df['Author Keywords'].fillna('') + ' ' + df['Index Keywords'].fillna('')\n",
        "\n",
        "# Define themes with associated keywords\n",
        "themes = {\n",
        "    \"Credit Scoring and Risk Assessment\": \"credit scoring, risk assessment, credit risk, creditworthiness\",\n",
        "    \"Fraud Detection and Anti-Money Laundering (AML)\": \"fraud detection, AML, anti-money laundering, anomaly detection, suspicious activities\",\n",
        "    \"Customer Service Automation and Personalization\": \"chatbots, virtual assistants, customer service, personalization\",\n",
        "    \"Predictive Analytics and Market Forecasting\": \"predictive analytics, market forecasting, time series, stock prices\",\n",
        "    \"Customer Churn Prediction and Retention\": \"churn prediction, customer retention, attrition, customer loyalty\",\n",
        "    \"Portfolio and Wealth Management\": \"portfolio management, wealth management, investment, robo-advisors\",\n",
        "    \"Operational Efficiency and Process Automation\": \"process automation, RPA, transaction verification, compliance\",\n",
        "    \"Sentiment Analysis and Financial Text Mining\": \"sentiment analysis, text mining, financial news, public perception\",\n",
        "    \"Regulatory Compliance and Risk Management\": \"regulatory compliance, risk management, compliance requirements\",\n",
        "    \"Financial Crime Detection and Cybersecurity\": \"cybersecurity, financial crime, digital security, cyber attacks\"\n",
        "}\n",
        "\n",
        "# Vectorize the text data\n",
        "tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_features=500)\n",
        "text_vectors = tfidf_vectorizer.fit_transform(df['Combined_Text'])\n",
        "\n",
        "# Apply KMeans clustering\n",
        "num_clusters = 10  # You can set this to a higher number if more clusters are needed\n",
        "kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
        "df['Cluster'] = kmeans.fit_predict(text_vectors)\n",
        "\n",
        "# Calculate theme vectors for cosine similarity comparison\n",
        "theme_vectors = tfidf_vectorizer.transform(themes.values())\n",
        "\n",
        "# Assign the closest theme to each cluster\n",
        "def assign_theme(cluster_num):\n",
        "    cluster_texts = df[df['Cluster'] == cluster_num]['Combined_Text']\n",
        "    cluster_vector = tfidf_vectorizer.transform(cluster_texts)\n",
        "    similarity_scores = cosine_similarity(cluster_vector.mean(axis=0), theme_vectors)\n",
        "    best_theme_idx = similarity_scores.argmax()\n",
        "    return list(themes.keys())[best_theme_idx]\n",
        "\n",
        "# Create a new column for Theme Category\n",
        "df['Category'] = df['Cluster'].apply(assign_theme)\n",
        "\n",
        "# Display the results\n",
        "df_result = df[['Title', 'Abstract', 'Category']]\n",
        "print(df_result.head())\n",
        "\n",
        "# Save the output to a new CSV\n",
        "df_result.to_csv(\"categorized_research_articles.csv\", index=False)\n",
        "print(\"Categorized research articles saved as 'categorized_research_articles.csv'\")\n",
        "```\n",
        "\n",
        "### Explanation of Key Steps\n",
        "\n",
        "1. **Concatenation**: Combine `Title`, `Abstract`, `Author Keywords`, and `Index Keywords` columns to maximize the text information for clustering.\n",
        "2. **TF-IDF Vectorization**: Converts text to numerical form, capturing the importance of words across documents.\n",
        "3. **KMeans Clustering**: Groups similar articles into clusters.\n",
        "4. **Cosine Similarity for Theme Assignment**: Compares each cluster with predefined themes and assigns the closest theme as the category.\n",
        "\n",
        "### Usage\n",
        "\n",
        "- Run this code in a Google Colab notebook or local Python environment.\n",
        "- Ensure the CSV file is uploaded and accessible.\n",
        "- The output file `categorized_research_articles.csv` will contain each article with a new `Category` column.\n",
        "\n",
        "This approach provides an automated and data-driven way to categorize articles based on clustering and thematic similarity, which you can then refine based on your domain knowledge."
      ],
      "metadata": {
        "id": "wCN9rLbkCJIJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "7lKDVLWvCQ2y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7AuDvtmHB7o0"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Load the data\n",
        "df = pd.read_csv(\"scopus_198 - selected columns.csv\")\n",
        "\n",
        "# Combine all text columns for clustering\n",
        "df['Combined_Text'] = df['Title'].fillna('') + ' ' + df['Abstract'].fillna('') + ' ' + df['Author Keywords'].fillna('') + ' ' + df['Index Keywords'].fillna('')\n",
        "\n",
        "# Define themes with associated keywords\n",
        "themes = {\n",
        "    \"Credit Scoring and Risk Assessment\": \"credit scoring, risk assessment, credit risk, creditworthiness\",\n",
        "    \"Fraud Detection and Anti-Money Laundering (AML)\": \"fraud detection, AML, anti-money laundering, anomaly detection, suspicious activities\",\n",
        "    \"Customer Service Automation and Personalization\": \"chatbots, virtual assistants, customer service, personalization\",\n",
        "    \"Predictive Analytics and Market Forecasting\": \"predictive analytics, market forecasting, time series, stock prices\",\n",
        "    \"Customer Churn Prediction and Retention\": \"churn prediction, customer retention, attrition, customer loyalty\",\n",
        "    \"Portfolio and Wealth Management\": \"portfolio management, wealth management, investment, robo-advisors\",\n",
        "    \"Operational Efficiency and Process Automation\": \"process automation, RPA, transaction verification, compliance\",\n",
        "    \"Sentiment Analysis and Financial Text Mining\": \"sentiment analysis, text mining, financial news, public perception\",\n",
        "    \"Regulatory Compliance and Risk Management\": \"regulatory compliance, risk management, compliance requirements\",\n",
        "    \"Financial Crime Detection and Cybersecurity\": \"cybersecurity, financial crime, digital security, cyber attacks\"\n",
        "}\n",
        "\n",
        "# Vectorize the text data\n",
        "tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_features=500)\n",
        "text_vectors = tfidf_vectorizer.fit_transform(df['Combined_Text'])\n",
        "\n",
        "# Apply KMeans clustering\n",
        "num_clusters = 10  # You can set this to a higher number if more clusters are needed\n",
        "kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
        "df['Cluster'] = kmeans.fit_predict(text_vectors)\n",
        "\n",
        "# Calculate theme vectors for cosine similarity comparison\n",
        "theme_vectors = tfidf_vectorizer.transform(themes.values())\n",
        "\n",
        "# Assign the closest theme to each cluster\n",
        "def assign_theme(cluster_num):\n",
        "    cluster_texts = df[df['Cluster'] == cluster_num]['Combined_Text']\n",
        "    cluster_vector = tfidf_vectorizer.transform(cluster_texts)\n",
        "    similarity_scores = cosine_similarity(cluster_vector.mean(axis=0), theme_vectors)\n",
        "    best_theme_idx = similarity_scores.argmax()\n",
        "    return list(themes.keys())[best_theme_idx]\n",
        "\n",
        "# Create a new column for Theme Category\n",
        "df['Category'] = df['Cluster'].apply(assign_theme)\n",
        "\n",
        "# Display the results\n",
        "df_result = df[['Title', 'Abstract', 'Category']]\n",
        "print(df_result.head())\n",
        "\n",
        "# Save the output to a new CSV\n",
        "df_result.to_csv(\"categorized_research_articles.csv\", index=False)\n",
        "print(\"Categorized research articles saved as 'categorized_research_articles.csv'\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4iC3dIMoCDh8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}